{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mvdr.toy_data.joint_fact_model import sample_joint_factor_model\n",
    "from mvdr.linalg_utils import rand_orthog\n",
    "from mvdr.principal_angles import get_principal_angles, subspace_dist\n",
    "from mvdr.mcca.mcca import MCCA\n",
    "from mvdr.mcca.k_mcca import KMCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample data from a joint factor model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_rank = 3\n",
    "n_samples = 1000\n",
    "n_features=[10, 20, 30]\n",
    "n_blocks = len(n_features)\n",
    "\n",
    "Xs, U_true, Ws_true = sample_joint_factor_model(n_samples=n_samples, n_features=n_features,\n",
    "                                                joint_rank=joint_rank,\n",
    "                                                m=5, noise_std=1, # these control the difficulty of the problem\n",
    "                                                random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit MCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default is no regularization meaning this is SUMCORR-AVGVAR MCCA\n",
    "mcca = MCCA(n_components=joint_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the fit-transform method outputs the common normalized scores (CNS)\n",
    "common_normalized_scores = mcca.fit_transform(Xs)\n",
    "\n",
    "# applying transform to the original data also gives the CNS\n",
    "common_normalized_scores = mcca.transform(Xs)\n",
    "\n",
    "# the block information (e.g. block loadings) are stored in the blocks_ attribute\n",
    "b = 0\n",
    "mcca.blocks_[b].block_loadings_\n",
    "mcca.blocks_[b].block_scores_\n",
    "\n",
    "# the blocks_ attribute can project new data from each view\n",
    "np.allclose(mcca.blocks_[b].transform(Xs[b]),\n",
    "            mcca.blocks_[b].block_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal angles for view 0 are [3.25948008 5.48505734 7.66368219] degrees\n",
      "Principal angles for view 1 are [ 7.05754975 10.33635925 11.51632033] degrees\n",
      "Principal angles for view 2 are [10.3777501  12.81570617 13.96373189] degrees\n"
     ]
    }
   ],
   "source": [
    "# lets see how accurately we can estimate the true loadings!\n",
    "def summarize_loading_acc(mcca, Ws_true):\n",
    "    \"\"\"\n",
    "    Prints the vector of principal angles comparing the\n",
    "    subspace spanned by the estimated block loadings\n",
    "    with the subspace spanned by the true block loadings.\n",
    "    \"\"\"\n",
    "    \n",
    "    for b in range(mcca.n_blocks_):\n",
    "        est_block_loadings = mcca.block_loadings_[b]\n",
    "        true_block_loadings = Ws_true[b]\n",
    "        theta = get_principal_angles(est_block_loadings, true_block_loadings,\n",
    "                                     is_ortho=False, deg=True)\n",
    "        print(\"Principal angles for view {} are {} degrees\".format(b, theta))\n",
    "        \n",
    "summarize_loading_acc(mcca, Ws_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCCA with regularization\n",
    "\n",
    "We can add regularization with the `regs` argument to handle high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal angles for view 0 are [3.25667814 5.47941317 7.65637561] degrees\n",
      "Principal angles for view 1 are [ 7.05073776 10.32607509 11.50648371] degrees\n",
      "Principal angles for view 2 are [10.3677296  12.80431272 13.95209547] degrees\n"
     ]
    }
   ],
   "source": [
    "# regularization value of .1 for each block\n",
    "mcca = MCCA(n_components=joint_rank, regs=.5).fit(Xs)\n",
    "\n",
    "# we can provide different regularization values for each block \n",
    "# by passing in a list\n",
    "# mcca = MCCA(n_components=joint_rank, regs=[.1, .2, .3]).fit(Xs)\n",
    "\n",
    "# a simple default regularization valuae can be obtained\n",
    "# using the Ledoit Wolf method for regularized covariance matrix estimation\n",
    "# mcca = MCCA(n_components=joint_rank, regs='lw').fit(Xs)\n",
    "\n",
    "summarize_loading_acc(mcca, Ws_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informative MCCA: PCA then MCCA\n",
    "\n",
    "We can also handle high-dimensional data with i-MCCA. We first compute a low rank PCA for each block, then run MCCA on the reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal angles for view 0 are [1.08226889 1.52126199 5.58547933] degrees\n",
      "Principal angles for view 1 are [2.11139036 3.15782628 4.37740522] degrees\n",
      "Principal angles for view 2 are [2.56143066 4.01880307 5.75075158] degrees\n"
     ]
    }
   ],
   "source": [
    "# i-MCCA where we first extract the first 5 PCs from each data block\n",
    "mcca = MCCA(n_components=joint_rank, signal_ranks=[5, 5, 5]).fit(Xs)\n",
    "summarize_loading_acc(mcca, Ws_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Kernel-MCCA\n",
    "\n",
    "We can compute kernel MCCA with the KMCCA() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit kernel MCCA with a linear kernel\n",
    "kmcca = KMCCA(n_components=joint_rank, kernel='linear').fit(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the common normalized scores or kmcca with linear kernel\n",
    "# should be the same as the common normalized scores for MCCA\n",
    "mcca = MCCA(n_components=joint_rank).fit(Xs)\n",
    "np.allclose(mcca.common_norm_scores_, kmcca.common_norm_scores_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mvdr] *",
   "language": "python",
   "name": "conda-env-mvdr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
